{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "69ea58ba",
   "metadata": {},
   "source": [
    "# What is Cross-Entropy Loss?\n",
    "\n",
    "<p> When your model predicts probabilities (like 0.9 for cat, 0.1 for dog),\n",
    "you need a way to measure how close those probabilities are to the true labels.</p>\n",
    "\n",
    "<p>Thatâ€™s where Cross-Entropy Loss (also called Log Loss) comes in.</p>\n",
    "\n",
    "<p>It measures how uncertain or wrong your predicted probability is.</p>"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
